# ğŸ“¡ RFID-RAG
AI-Powered Retrieval-Augmented Generation System for RFID Knowledge

RFID-RAG is an AI-based question-answering system designed to deliver accurate, contextual, and natural answers for RFID (Radio Frequency Identification) topics.

This project combines semantic vector search, a curated local knowledge base, large language models (LLMs), and an online search fallback to ensure reliable answers even when local knowledge is incomplete.

---

## âœ¨ Features

- ğŸ” Semantic vector search (meaning-based, not keyword-based)
- ğŸ§  Hybrid RAG architecture (Local KB + Online Search + LLM)
- ğŸŒ Online search fallback when confidence is low
- ğŸ—‚ï¸ Human-in-the-loop knowledge approval system
- ğŸ“Š Confidence score for every answer
- ğŸ”Œ API-first design (easy integration with web, WhatsApp, Telegram, n8n)
- ğŸ’» Runs on CPU (no GPU required)

---

## ğŸ—ï¸ System Architecture

User Question
â†“
Vector Search (Local Knowledge Base)
â†“
Confidence Evaluation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ High Confidence â”‚ â†’ Local RAG Answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Low Confidence â”‚ â†’ Online Search â†’ LLM
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
(Optional) Save to Pending Knowledge Base


---

## ğŸ“ Project Structure

rfid-rag/
â”‚
â”œâ”€â”€ app.py # FastAPI entry point
â”œâ”€â”€ rag.py # Core RAG engine
â”œâ”€â”€ vectorstore.py # Vector similarity search
â”œâ”€â”€ online_search.py # Online search logic
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ data.json # Approved knowledge base
â”‚ â””â”€â”€ data_pending.json # Pending (online) data
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Tech Stack

| Layer | Technology |
|-----|-----------|
| API | FastAPI |
| LLM | Mistral (via Ollama) |
| Embeddings | Sentence Transformers |
| Vector Search | Cosine Similarity |
| Search | DuckDuckGo / Custom Search API |
| Storage | JSON Knowledge Base |
| Deployment | CPU-only |

---

## ğŸš€ Getting Started (Conda Environment)

### 1. Install Conda
Recommended: Miniconda  
https://docs.conda.io/en/latest/miniconda.html

---

### 2. Create Conda Environment

```bash
conda create -n rfid-rag python=3.10 -y
conda activate rfid-rag
```

---

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```
### 4. Install & Run Ollama
Install Ollama:
https://ollama.com

Pull LLM model:
```bash
ollama pull mistral
```
Run Ollama server:
```bash
ollama serve
```
Ollama runs at:

```bash
Ollama runs at:
```

### 5. Run the API Server

```bash
uvicorn app:app --reload
```
API will be available at:

```bash
http://localhost:8000
```

## Knowledge Workflow
1. User asks a question
2. System performs semantic vector search
3. If confidence is low:
   - Online search is triggered
   - LLM generates an answer
4. Online answers are saved to:
```bash
data/data_pending.json
```
5. data/data_pending.json
6. Approved knowledge is stored in:
```bash
data/data.json
```
